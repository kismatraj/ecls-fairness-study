{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Exploration\n",
    "\n",
    "This notebook explores the ECLS-K:2011 public-use data for the fairness study.\n",
    "\n",
    "## Objectives\n",
    "1. Load and inspect the data\n",
    "2. Check variable availability and missing rates\n",
    "3. Generate descriptive statistics\n",
    "4. Create analytic sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.data_loader import (\n",
    "    load_config,\n",
    "    load_ecls_data,\n",
    "    handle_missing_values,\n",
    "    create_race_variable,\n",
    "    create_ses_variable,\n",
    "    get_variable_lists\n",
    ")\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = load_config('../config.yaml')\n",
    "vars = get_variable_lists(config)\n",
    "\n",
    "print(\"Outcome variables:\", vars['outcomes'])\n",
    "print(\"Demographic variables:\", vars['demographics'])\n",
    "print(\"Number of predictors:\", len(vars['predictors']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "**Note:** You need to download the ECLS-K:2011 data first from:\n",
    "https://nces.ed.gov/ecls/dataproducts.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data exists\n",
    "data_path = Path('../data/processed/analytic_sample.parquet')\n",
    "raw_path = Path('../data/raw/')\n",
    "\n",
    "if data_path.exists():\n",
    "    print(f\"Loading processed data from {data_path}\")\n",
    "    df = pd.read_parquet(data_path)\n",
    "elif list(raw_path.glob('*.csv')) or list(raw_path.glob('*.dat')):\n",
    "    print(\"Loading raw data...\")\n",
    "    # df = load_ecls_data(str(raw_path / 'your_data_file.csv'))\n",
    "    print(\"Please update the file path above\")\n",
    "else:\n",
    "    print(\"Data not found. Please download from NCES:\")\n",
    "    print(\"https://nces.ed.gov/ecls/dataproducts.asp\")\n",
    "    print(\"\\nFor now, creating synthetic data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n = 5000\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        # Demographics\n",
    "        'X_RACETH_R': np.random.choice([1, 2, 3, 4, 7], n, p=[0.5, 0.15, 0.25, 0.05, 0.05]),\n",
    "        'X_CHSEX_R': np.random.choice([1, 2], n),\n",
    "        'X1SESQ5': np.random.choice([1, 2, 3, 4, 5], n),\n",
    "        'X12LANGST': np.random.choice([1, 2], n, p=[0.8, 0.2]),\n",
    "        \n",
    "        # Baseline scores\n",
    "        'X1RTHETK': np.random.normal(0, 1, n),\n",
    "        'X2RTHETK': np.random.normal(0.2, 1, n),\n",
    "        'X1MTHETK': np.random.normal(0, 1, n),\n",
    "        'X2MTHETK': np.random.normal(0.2, 1, n),\n",
    "        \n",
    "        # Executive function\n",
    "        'X4DCCSSCR': np.random.normal(50, 10, n),\n",
    "        'X6DCCSSCR': np.random.normal(55, 10, n),\n",
    "        \n",
    "        # Approaches to learning\n",
    "        'X1TCHAPP': np.random.normal(3, 0.5, n),\n",
    "        'X2TCHAPP': np.random.normal(3.1, 0.5, n),\n",
    "        \n",
    "        # Outcomes\n",
    "        'X9RTHETA': np.random.normal(1.5, 1, n),\n",
    "        'X9MTHETA': np.random.normal(1.5, 1, n)\n",
    "    })\n",
    "    \n",
    "    print(f\"Created synthetic data with {len(df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn types:\\n{df.dtypes.value_counts()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data summary\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(1)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct\n",
    "}).sort_values('Missing %', ascending=False)\n",
    "\n",
    "print(\"Variables with missing data:\")\n",
    "print(missing_df[missing_df['Missing Count'] > 0].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Derived Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df = handle_missing_values(df)\n",
    "\n",
    "# Create race variable\n",
    "df = create_race_variable(df)\n",
    "\n",
    "# Create SES variable\n",
    "df = create_ses_variable(df)\n",
    "\n",
    "print(\"New variables created:\")\n",
    "print(df[['race_ethnicity', 'ses_category']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Race/ethnicity distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Race\n",
    "race_counts = df['race_ethnicity'].value_counts()\n",
    "axes[0].bar(race_counts.index, race_counts.values, color='steelblue')\n",
    "axes[0].set_title('Race/Ethnicity Distribution')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# SES\n",
    "ses_counts = df['ses_category'].value_counts().sort_index()\n",
    "axes[1].bar(ses_counts.index, ses_counts.values, color='coral')\n",
    "axes[1].set_title('SES Distribution')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome distributions by race\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Reading\n",
    "sns.boxplot(data=df, x='race_ethnicity', y='X9RTHETA', ax=axes[0])\n",
    "axes[0].set_title('5th Grade Reading Scores by Race/Ethnicity')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Math\n",
    "sns.boxplot(data=df, x='race_ethnicity', y='X9MTHETA', ax=axes[1])\n",
    "axes[1].set_title('5th Grade Math Scores by Race/Ethnicity')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "numeric_cols = ['X1RTHETK', 'X2RTHETK', 'X1MTHETK', 'X9RTHETA', 'X9MTHETA']\n",
    "available_cols = [c for c in numeric_cols if c in df.columns]\n",
    "\n",
    "if len(available_cols) > 1:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        df[available_cols].corr(),\n",
    "        annot=True,\n",
    "        cmap='coolwarm',\n",
    "        center=0,\n",
    "        fmt='.2f'\n",
    "    )\n",
    "    plt.title('Correlation Between Cognitive Scores')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create At-Risk Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import create_at_risk_indicator\n",
    "\n",
    "# Create at-risk indicator (< 25th percentile)\n",
    "df = create_at_risk_indicator(df, 'X9RTHETA', percentile=25)\n",
    "\n",
    "# Check prevalence by group\n",
    "prevalence = df.groupby('race_ethnicity')['X9RTHETA_at_risk'].agg(['mean', 'count'])\n",
    "prevalence.columns = ['At-Risk Rate', 'N']\n",
    "prevalence['At-Risk Rate'] = (prevalence['At-Risk Rate'] * 100).round(1).astype(str) + '%'\n",
    "print(\"At-Risk Prevalence by Race/Ethnicity:\")\n",
    "print(prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to parquet\n",
    "output_path = Path('../data/processed/')\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df.to_parquet(output_path / 'analytic_sample.parquet')\n",
    "print(f\"Saved {len(df)} records to {output_path / 'analytic_sample.parquet'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **02_model_development.ipynb** - Train and evaluate ML models\n",
    "2. **03_fairness_analysis.ipynb** - Evaluate algorithmic fairness\n",
    "3. **04_results_summary.ipynb** - Generate final figures and tables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
